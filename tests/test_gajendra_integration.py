"""
GAJENDRA MOKSHA INTEGRATION TEST
=================================

This test demonstrates the integration of CRITICAL priority bypass
with the API Gateway and Kernel.

When the API Gateway receives a response with status="critical",
it should invoke the kernel directly, bypassing all queue layers.
"""

import json
from envoy.tools.milk_ocean import MilkOceanRouter


def test_critical_response_signals_kernel_bypass():
    """
    Verify that CRITICAL priority responses signal kernel to bypass queue.

    This response structure is consumed by the API Gateway to route
    the request directly to the Kernel (Vishnu).
    """
    router = MilkOceanRouter()

    # Send CRITICAL request
    result = router.process_prayer(
        "CRITICAL: Database failover - activate emergency mode!",
        agent_id="system_monitor",
        critical=True,
    )

    # API Gateway reads these fields to decide routing
    assert result["status"] == "critical", "API Gateway reads status=critical"
    assert result["bypass_queue"] == True, "Signal: queue should be bypassed"
    assert result["path"] == "kernel_direct", "Routing path is direct to kernel"
    assert result["action"] == "INVOKE_KERNEL_DIRECT", "Explicit kernel invocation"

    # The kernel response should not be queued
    # In real implementation, API Gateway would do:
    # if result["status"] == "critical":
    #     response = kernel.invoke_directly(request.message)
    #     return response
    # else:
    #     # normal queue processing

    print("‚úÖ Integration test passed: CRITICAL priority gateway integration confirmed")


def test_gajendra_protocol_full_scenario():
    """
    Full Gajendra Moksha protocol scenario:
    1. Under normal conditions, requests are routed intelligently
    2. Under attack/load, LOW priority requests queue
    3. CRITICAL request bypasses queue instantly
    4. Kernel is invoked directly for CRITICAL requests
    """
    router = MilkOceanRouter()

    # Scenario: Normal load
    print("\nüìä Scenario: Normal Operation")
    normal_result = router.process_prayer(
        "What is the current system status?", agent_id="monitoring_service"
    )
    assert normal_result["status"] == "routing", "Normal request routes normally"
    print(f"  ‚úì Normal request: {normal_result['path']}")

    # Scenario: DDoS attack (fill queue)
    print("\nüêä Scenario: DDoS Attack - Queue Fills")
    for i in range(50):
        router.process_prayer(f"Batch job {i}", agent_id="attacker", critical=False)
    queue_status = router.get_queue_status()
    print(f"  ‚úì Queue size: {queue_status['ocean_status']['total']} requests")

    # Scenario: Critical alert during attack
    print("\nüêò Scenario: Gajendra Sends Lotus Flower (critical=True)")
    critical_result = router.process_prayer(
        "CRITICAL: Emergency security response needed NOW!",
        agent_id="security_admin",
        critical=True,
    )

    # Verify critical response
    assert critical_result["status"] == "critical"
    assert critical_result["bypass_queue"] == True
    print(
        f"  ‚úì CRITICAL request bypasses {queue_status['ocean_status']['total']} queued items"
    )
    print(f"  ‚úì Kernel invoked directly: {critical_result['action']}")

    # Verify queue was not modified
    final_status = router.get_queue_status()
    assert (
        final_status["ocean_status"]["total"] == queue_status["ocean_status"]["total"]
    )
    print(f"  ‚úì Queue unchanged: still {final_status['ocean_status']['total']} items")

    print("\n‚úÖ Full Gajendra Moksha protocol verified!")


if __name__ == "__main__":
    test_critical_response_signals_kernel_bypass()
    test_gajendra_protocol_full_scenario()
